import re
import json
import os
import time
import uuid
import base64
import hashlib
from collections.abc import Generator
from typing import Any

from utils.tools import (
    _build_prompt_message_tools,
    _download_file_content,
    _extract_first_json_object,
    _extract_url_and_name,
    _guess_mime_type,
    _infer_ext_from_url,
    _is_allow_reply,
    _is_deny_reply,
    _list_dir,
    _parse_tool_call,
    _safe_filename,
    _safe_get,
    _safe_join,
    _shorten_text,
    _split_message_content,
 )

from utils.skill_agent_constants import HISTORY_TRANSCRIPT_MAX_CHARS
from utils.skill_agent_debug import _dbg, _model_brief
from utils.skill_agent_exec import _cleanup_old_temp_sessions, _detect_skills_root
from utils.skill_agent_runtime import _AgentRuntime
from utils.skill_agent_schemas import TOOL_SCHEMAS, _tool_call_retry_prompt, _validate_tool_arguments
from utils.skill_agent_storage import (
    _append_history_turn,
    _get_history_storage_key,
    _get_resume_storage_key,
    _get_session_dir_storage_key,
    _storage_get_json,
    _storage_get_text,
    _storage_set_json,
    _storage_set_text,
)
from utils.skill_agent_uploads import _build_uploads_context

from dify_plugin import Tool
from dify_plugin.entities.model.message import (
    AssistantPromptMessage,
    PromptMessageTool,
    SystemPromptMessage,
    ToolPromptMessage,
    UserPromptMessage,
)
from dify_plugin.entities.tool import ToolInvokeMessage

class SkillAgentTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        model = tool_parameters.get("model")
        query = tool_parameters.get("query")
        max_steps = int(tool_parameters.get("max_steps") or 8)
        memory_turns = int(tool_parameters.get("memory_turns") or 10)
        history_turns = int(tool_parameters.get("history_turns") or 0)
        system_prompt = tool_parameters.get("system_prompt") or "ä½ æ˜¯ä¸€ä¸ªxxxx"
        skills_root = _detect_skills_root(tool_parameters.get("skills_root"))

        if not query or not isinstance(query, str):
            yield self.create_text_message("âŒç¼ºå°‘ query å‚æ•°\n")
            return
        user_input = str(query)

        storage = self.session.storage
        resume_key = _get_resume_storage_key(self.session)
        history_key = _get_history_storage_key(self.session)
        session_dir_key = _get_session_dir_storage_key(self.session)
        resume_state = _storage_get_json(storage, resume_key)
        resume_pending = bool(resume_state.get("pending"))
        is_resuming = False

        plugin_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
        temp_root = os.path.join(plugin_root, "temp")
        os.makedirs(temp_root, exist_ok=True)
        persisted_session_dir = _storage_get_text(storage, session_dir_key).strip()
        if persisted_session_dir and os.path.isdir(persisted_session_dir):
            session_dir = persisted_session_dir
        else:
            session_dir = os.path.join(temp_root, f"dify-skill-{uuid.uuid4().hex[:8]}-")
        resume_context = ""

        if resume_pending and _is_deny_reply(user_input):
            _storage_set_json(storage, resume_key, None)
            yield self.create_text_message("ğŸ¤å·²æ”¶åˆ°ä½ çš„æ‹’ç»ï¼Œæœ¬æ¬¡ä¸ä¼šåœ¨ temp ç›®å½•åˆ›å»ºè„šæœ¬ç»§ç»­æ‰§è¡Œã€‚\n")
            return
        if resume_pending and _is_allow_reply(user_input):
            candidate = str(resume_state.get("session_dir") or "").strip()
            if candidate:
                session_dir = candidate
                os.makedirs(session_dir, exist_ok=True)
                _storage_set_text(storage, session_dir_key, session_dir)
                original_query_for_resume = str(resume_state.get("original_query") or "").strip()
                if original_query_for_resume:
                    query = original_query_for_resume
                is_resuming = True
                _storage_set_json(storage, resume_key, None)
                resume_context = (
                    "\n\n[ç»­è·‘æˆæƒ]\n"
                    + "ç”¨æˆ·å·²æ˜ç¡®å…è®¸ä½ åœ¨ temp ä¼šè¯ç›®å½•ä¸­è‡ªè¡Œåˆ›å»ºè„šæœ¬ã€å¿…è¦æ—¶å®‰è£…ä¾èµ–ï¼Œå¹¶ç»§ç»­ä¸Šä¸€è½®æœªå®Œæˆçš„ç”Ÿæˆã€‚\n"
                    + "è¯·ç›´æ¥åŸºäºå½“å‰ temp ä¼šè¯ç›®å½•ä¸­çš„ä¸­é—´äº§ç‰©ç»§ç»­æ¨è¿›ï¼Œä¼˜å…ˆç”Ÿæˆæœ€ç»ˆå¯äº¤ä»˜æ–‡ä»¶ã€‚\n"
                )
        os.makedirs(session_dir, exist_ok=True)
        _storage_set_text(storage, session_dir_key, session_dir)
        if not is_resuming:
            _cleanup_old_temp_sessions(temp_root, keep=4, protect_dirs={session_dir})

        file_items: list[Any] = []
        files_param = tool_parameters.get("files")
        if isinstance(files_param, list):
            file_items = [x for x in files_param if x]
        elif files_param:
            file_items = [files_param]
        elif tool_parameters.get("file"):
            file_items = [tool_parameters.get("file")]

        uploads_context = ""
        if file_items:
            uploads_dir = _safe_join(session_dir, "uploads")
            os.makedirs(uploads_dir, exist_ok=True)
            uploaded: list[dict[str, Any]] = []
            for item in file_items:
                url, name = _extract_url_and_name(item)
                if not url:
                    yield self.create_text_message("âŒæœªèƒ½è·å–ä¸Šä¼ æ–‡ä»¶ URLï¼ˆfiles[i].urlï¼‰ã€‚\n")
                    return
                try:
                    content = _download_file_content(str(url), timeout=45)
                except Exception as e:
                    yield self.create_text_message(f"âŒæ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼š{str(e)}\n")
                    return
                ext = _infer_ext_from_url(str(url))
                filename = _safe_filename(str(name) if name else None, fallback_ext=ext)
                abs_path = os.path.join(uploads_dir, filename)
                try:
                    with open(abs_path, "wb") as f:
                        f.write(content)
                except Exception as e:
                    yield self.create_text_message(f"âŒä¿å­˜ä¸Šä¼ æ–‡ä»¶å¤±è´¥ï¼š{str(e)}\n")
                    return

                rel_path = f"uploads/{filename}"
                mime = None
                if isinstance(item, dict) and item.get("mime_type"):
                    mime = str(item.get("mime_type") or "").strip() or None
                if not mime:
                    try:
                        mime = _guess_mime_type(filename)
                    except Exception:
                        mime = None
                uploaded.append(
                    {
                        "relative_path": rel_path,
                        "bytes": len(content),
                        "mime_type": mime or "",
                        "filename": filename,
                        "source_url": str(url),
                    }
                )

            lines = ["\n\n[ä¸Šä¼ æ–‡ä»¶æ¸…å•]", "ä»¥ä¸‹è·¯å¾„å‡ç›¸å¯¹äºæœ¬æ¬¡ä¼šè¯çš„ session_dirï¼š"]
            for f in uploaded:
                lines.append(
                    f"- {f.get('relative_path')} | mime={f.get('mime_type') or ''} | bytes={f.get('bytes') or 0} | filename={f.get('filename') or ''}"
                )
            uploads_context = "\n".join(lines) + "\n"
        else:
            uploads_dir = _safe_join(session_dir, "uploads")
            os.makedirs(uploads_dir, exist_ok=True)

        uploads_context = _build_uploads_context(session_dir)

        runtime = _AgentRuntime(
            skills_root=skills_root,
            session_dir=session_dir,
            max_steps=max_steps,
            memory_turns=memory_turns,
        )

        history_messages: list[Any] = []
        if history_turns > 0:
            history_state = _storage_get_json(storage, history_key)
            turns = history_state.get("turns")
            if isinstance(turns, list) and turns:
                picked: list[tuple[str, str]] = []
                for t in reversed(turns[-history_turns:]):
                    if not isinstance(t, dict):
                        continue
                    u = str(t.get("user") or "").strip()
                    a = str(t.get("assistant") or "").strip()
                    if not u and not a:
                        continue
                    picked.append((u, a))
                if picked:
                    acc: list[tuple[str, str]] = []
                    total = 0
                    for u, a in picked:
                        block_len = len(u) + len(a)
                        if total + block_len > HISTORY_TRANSCRIPT_MAX_CHARS and acc:
                            break
                        acc.append((u, a))
                        total += block_len
                        if total >= HISTORY_TRANSCRIPT_MAX_CHARS:
                            break
                    acc.reverse()
                    for u, a in acc:
                        if u:
                            history_messages.append(UserPromptMessage(content=u))
                        if a:
                            history_messages.append(AssistantPromptMessage(content=a))

        skills_index = runtime.load_skills_index()
        try:
            skills_count = len(skills_index.get("skills") or []) if isinstance(skills_index, dict) else 0
        except Exception:
            skills_count = 0
        _dbg(
            "start "
            + _model_brief(model)
            + f" session_dir={session_dir} skills_root={skills_root!s} skills_count={skills_count} "
            + f"query_len={len(query)}"
        )
        system_content = (
            system_prompt.strip()
            + "\n\nä½ æ˜¯ä¸€ä¸ªä½¿ç”¨ Skills æ–‡ä»¶å¤¹ä½œä¸ºâ€œå·¥å…·ç®±â€çš„é€šç”¨å‹ Agentã€‚\n"
            + "\n[ä¼šè¯è·¯å¾„]\n"
            + f"- session_dir: {session_dir}\n"
            + f"- skills_root: {skills_root}\n"
            + "ä½ å¿…é¡»éµå¾ªæ¸è¿›å¼æŠ«éœ²æµç¨‹ï¼š\n"
            + "1) åªæ ¹æ®æŠ€èƒ½å…ƒæ•°æ®ï¼ˆname/descriptionï¼‰åˆ¤æ–­å¯èƒ½ç›¸å…³çš„æŠ€èƒ½\n"
            + "2) è§¦å‘æ—¶æ‰è°ƒç”¨ get_skill_metadata è¯»å– SKILL.mdï¼ˆè¯´æ˜æ–‡æ¡£ï¼‰\n"
            + "3) ä»»ä½•å¯¹æŠ€èƒ½çš„è¿›ä¸€æ­¥æ“ä½œï¼ˆlist_skill_files/read_skill_file/run_skill_commandï¼‰ä¹‹å‰ï¼Œå¿…é¡»å…ˆ get_skill_metadataï¼›è‹¥æœªæ‰§è¡Œï¼Œæœ¬ç³»ç»Ÿä¼šæ‹’ç»è¯¥è°ƒç”¨å¹¶è¦æ±‚ä½ å…ˆè¡¥è¯»è¯´æ˜ä¹¦ã€‚\n"
            + "4) æŒ‰è¯´æ˜ä¹¦å†…å®¹æ‰§è¡Œè„šæœ¬/å‘½ä»¤ï¼Œæˆ–è¿›ä¸€æ­¥æœç´¢èµ„æ–™å‰ï¼Œå¿…é¡»å…ˆè°ƒç”¨ list_skill_files æŸ¥çœ‹æŠ€èƒ½åŒ…çš„ç›®å½•ç»“æ„ï¼Œä»¥ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•æ‰§è¡Œå‘½ä»¤ã€‚\n"
            + "5) åªæœ‰åœ¨éœ€è¦æ›´æ·±ä¿¡æ¯æ—¶ï¼Œæ‰è°ƒç”¨ read_skill_file\n"
            + "6) åªæœ‰åœ¨æ˜ç¡®éœ€è¦æ‰§è¡Œè„šæœ¬/å‘½ä»¤æ—¶ï¼Œæ‰è°ƒç”¨ run_skill_command\n"
            + "7) æ‰§è¡Œå‰å¿…é¡»å…ˆç¡®è®¤æŠ€èƒ½åŒ…å†…ç¡®å®å­˜åœ¨å¯æ‰§è¡Œå…¥å£ï¼ˆè„šæœ¬/æ¨¡å—ç­‰ï¼‰ï¼Œä¸è¦çŒœæµ‹æ¨¡å—åï¼›å¦‚æœç¼ºå°‘å¯æ‰§è¡Œå…¥å£ï¼Œåˆ™å…ˆäº¤ä»˜å½“å‰å¯äº¤ä»˜äº§ç‰©ï¼Œå¹¶è¯¢é—®ç”¨æˆ·æ˜¯å¦å…è®¸ä½ åœ¨ temp ç›®å½•ä¸­è‡ªè¡Œåˆ›å»ºè„šæœ¬åå†å°è¯•ç”Ÿæˆã€‚\n"
            + "8) æŒ‰è¯´æ˜ä¹¦è¦æ±‚ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶åï¼Œå¿…é¡»ç”¨ export_temp_file æ ‡è®°æœ€ç»ˆæ–‡ä»¶\n"
            + "è·¯å¾„è§„åˆ™ï¼šuploads/ ä¸ä½ ç”¨ write_temp_file ç”Ÿæˆçš„ä¸­é—´äº§ç‰©éƒ½ä½äº session_dir ä¸‹ï¼›run_skill_command çš„ cwd åœ¨ skills_root/<skill_name> ä¸‹ã€‚\n"
            + "å› æ­¤ï¼šåªè¦å‘½ä»¤å‚æ•°éœ€è¦å¼•ç”¨ uploads/ æˆ– temp ä¸­é—´æ–‡ä»¶ï¼Œä¸€å¾‹ä½¿ç”¨ read_temp_file è¿”å›çš„ç»å¯¹è·¯å¾„ï¼ˆresult.pathï¼‰ä¼ ç»™å‘½ä»¤ï¼›ä¸è¦ä½¿ç”¨ ../uploadsã€../../temp è¿™ç±»ç›¸å¯¹è·¯å¾„çŒœæµ‹ã€‚\n"
            + "ä¾èµ–å®‰è£…è§„åˆ™ï¼šå¦‚éœ€ npm install/npm ci/bun installï¼Œå¿…é¡»ç”¨ run_skill_command åœ¨æŠ€èƒ½åŒ…å†…å« package.json çš„ç›®å½•æ‰§è¡Œï¼ˆé€šè¿‡ cwd_relative æŒ‡åˆ°è¯¥ç›®å½•ï¼‰ï¼›ç¦æ­¢åœ¨ session_dir æ‰§è¡Œ installï¼Œå¦åˆ™ä¼šå†™å…¥ temp/<session>/node_modules å¯¼è‡´æ¯æ¬¡ä¼šè¯é‡å¤å®‰è£…ã€‚\n"
            + "è¡¥å……è§„åˆ™1ï¼šå¦‚æœç”¨æˆ·è¯·æ±‚ä¸­å·²ç»æ˜ç¡®ç»™å‡ºå…·ä½“ç±»å‹/å‚æ•°ï¼Œåˆ™è§†ä¸ºå·²ç¡®è®¤ï¼Œä¸è¦é‡å¤è¿½é—®ï¼Œç›´æ¥è¿›å…¥å¯¹åº”åˆ†æ”¯æ‰§è¡Œã€‚\n"
            + "è¡¥å……è§„åˆ™2ï¼šå½“ä½ éœ€è¦å‘ç”¨æˆ·è¿½é—®ä»»ä½•ä¿¡æ¯æ—¶ï¼šæœ¬è½®å¿…é¡»åªè¾“å‡ºé—®é¢˜ä¸é€‰é¡¹ï¼Œå¹¶ç«‹åˆ»ç»“æŸï¼›ä¸å¾—åœ¨åŒä¸€è½®ç»§ç»­è¯»å–ä»»ä½•æ–‡ä»¶ã€æ‰§è¡Œä»»ä½•å‘½ä»¤ã€ç”Ÿæˆä»»ä½•äº§ç‰©ã€‚\n"
            + "è¡¥å……è§„åˆ™3ï¼šé»˜è®¤å€¼åªèƒ½åœ¨ç”¨æˆ·æ˜ç¡®è¯´â€˜é»˜è®¤/éšä¾¿/ä½ å†³å®šâ€™æ—¶å¯ç”¨ï¼›ç”¨æˆ·æœªå›å¤ä¸ç­‰äºé€‰æ‹©äº†é»˜è®¤ã€‚"
            + "è¡¥å……è§„åˆ™4ï¼šå½“ä½ å‡†å¤‡è°ƒç”¨ write_temp_file æ—¶ï¼Œå¿…é¡»å…ˆåœ¨è‡ªç„¶è¯­è¨€é‡Œè¾“å‡ºä¸€è¡Œâ€œå†™å…¥æ„å›¾ç¡®è®¤â€ï¼ŒåŒ…å«ï¼šrelative_path + å†…å®¹æ‘˜è¦ï¼ˆå‰ 80 å­—ï¼‰+ å¤§è‡´é•¿åº¦ï¼›ç„¶åå†å‘èµ·å·¥å…·è°ƒç”¨ã€‚relative_path å¿…é¡»æ˜¯æ–‡ä»¶è·¯å¾„ï¼ˆä¸èƒ½æ˜¯ç©ºã€'.'ã€'..'ã€ä¸èƒ½ä»¥ '/' ç»“å°¾ï¼Œä¸èƒ½æŒ‡å‘ç›®å½•ï¼‰ã€‚\n"
            + (uploads_context or "")
            + "ä½ å¿…é¡»æŠŠå®ç°è¿‡ç¨‹ä¸­çš„ä¸­é—´äº§ç‰©å†™å…¥ temp ä¼šè¯ç›®å½•ï¼ˆè„šæœ¬ã€è‰ç¨¿ã€ç”Ÿæˆç‰©ç­‰ï¼‰ï¼š\n"
            + "- å†™æ–‡æœ¬ï¼šwrite_temp_file\n"
            + "- è¿è¡Œå‘½ä»¤ç”Ÿæˆæ–‡ä»¶ï¼šrun_temp_command\n"
            + "å¯¹ä»»ä½•â€œæœ‰æ˜ç¡®äº¤ä»˜ç‰©â€çš„è¯·æ±‚ï¼Œä½ å¿…é¡»åœ¨åŒä¸€è½®å†…æ¨è¿›ç›´åˆ°ï¼šç”Ÿæˆå¯äº¤ä»˜æ–‡ä»¶ï¼Œæˆ–ç»™å‡ºæ˜ç¡®å¤±è´¥åŸå› ã€‚\n"
            + "åªæœ‰è°ƒç”¨ export_temp_file æ ‡è®°çš„æ–‡ä»¶ï¼Œæ‰ä¼šä½œä¸ºæœ€ç»ˆäº¤ä»˜æ–‡ä»¶è¿”å›ç»™ç”¨æˆ·ï¼›uploads/ ä¸æœªæ ‡è®°æ–‡ä»¶ä¸ä¼šå›ä¼ ã€‚\n\n"
            + "å¯ç”¨åŠ¨ä½œï¼š\n"
            + "- get_session_context()\n"
            + "- get_skill_metadata(skill_name)\n"
            + "- list_skill_files(skill_name, max_depth)\n"
            + "- read_skill_file(skill_name, relative_path, max_chars)\n"
            + "- run_skill_command(skill_name, command, cwd_relative, auto_install)\n"
            + "- write_temp_file(relative_path, content)\n"
            + "- read_temp_file(relative_path, max_chars)\n"
            + "- list_temp_files(max_depth)\n"
            + "- run_temp_command(command, cwd_relative, auto_install)\n"
            + "- export_temp_file(temp_relative_path, workspace_relative_path, overwrite)  # ä¸å¤åˆ¶ï¼Œä»…æ ‡è®°äº¤ä»˜å\n\n"
            + "å¦‚æœæ¨¡å‹æ”¯æŒ function callï¼Œè¯·ç›´æ¥å‘èµ·å·¥å…·è°ƒç”¨ï¼›è‹¥ä¸æ”¯æŒï¼Œåˆ™ç”¨ JSON åè®®å“åº”ï¼š\n"
            + '{"type":"tool","name":"get_skill_metadata","arguments":{"skill_name":"xxx"}}\n'
            + 'æˆ– {"type":"final","content":"..."}\n\n'
            + "æŠ€èƒ½ç´¢å¼•ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æŠ€èƒ½ï¼‰ï¼š\n"
            + json.dumps(skills_index, ensure_ascii=False)
            + (resume_context or "")
        )

        messages: list[Any] = [SystemPromptMessage(content=system_content)]
        if history_messages:
            messages.extend(history_messages)
        messages.append(UserPromptMessage(content=query))

        def compact() -> None:
            if memory_turns <= 0:
                return
            keep = 1 + memory_turns * 4
            if len(messages) > keep:
                system_msg = messages[0]
                tail = messages[-(keep - 1) :]
                messages[:] = [system_msg, *tail]

        final_text: str | None = None
        final_file_meta: dict[str, dict[str, str]] = {}
        empty_responses = 0
        saved_asset_fingerprints: set[str] = set()
        resume_saved = False
        final_text_already_streamed = False

        def stream_text_to_user(text: str, chunk_size: int = 8) -> Generator[ToolInvokeMessage]:
            s = (text or "").strip()
            if not s:
                return
            step = max(1, int(chunk_size))
            for i in range(0, len(s), step):
                yield self.create_text_message(s[i : i + step])

        def redact_user_visible_text(text: str) -> str:
            s = str(text or "")
            if not s:
                return s
            for p in [session_dir, skills_root]:
                if p and isinstance(p, str):
                    s = s.replace(p, "<REDACTED_PATH>")
                    s = s.replace(p.replace("\\", "/"), "<REDACTED_PATH>")
            s = re.sub(r"[A-Za-z]:\\[^\s\r\n\t\"']+", "<REDACTED_PATH>", s)
            s = re.sub(r"/[^\s\r\n\t\"']+", "<REDACTED_PATH>", s)
            return s

        def persist_llm_assets(parts: Any) -> list[str]:
            if not parts or not isinstance(parts, list):
                return []
            saved: list[str] = []
            out_dir = _safe_join(session_dir, "llm_assets")
            os.makedirs(out_dir, exist_ok=True)
            for i, item in enumerate(parts):
                if not isinstance(item, dict):
                    continue
                item_type = str(item.get("type") or "")
                if item_type not in {"image", "document", "audio", "video"}:
                    continue
                mime = str(item.get("mime_type") or "")
                filename = str(item.get("filename") or "").strip()
                url = str(item.get("url") or item.get("data") or "").strip()
                b64 = str(item.get("base64_data") or "").strip()
                raw: bytes | None = None
                if b64:
                    try:
                        raw = base64.b64decode(b64, validate=False)
                    except Exception:
                        raw = None
                if raw is None and url.startswith("data:") and ";base64," in url:
                    try:
                        header, payload = url.split(";base64,", 1)
                        if not mime and header.startswith("data:"):
                            mime = header[5:]
                        raw = base64.b64decode(payload, validate=False)
                    except Exception:
                        raw = None
                if raw is None:
                    continue
                try:
                    fp = hashlib.sha1(raw).hexdigest()
                    key = f"{item_type}|{mime}|{fp}"
                except Exception:
                    key = f"{item_type}|{mime}|{len(raw)}"
                if key in saved_asset_fingerprints:
                    continue
                saved_asset_fingerprints.add(key)
                if not filename:
                    ext = ""
                    if mime:
                        if "png" in mime:
                            ext = ".png"
                        elif "jpeg" in mime or "jpg" in mime:
                            ext = ".jpg"
                        elif "pdf" in mime:
                            ext = ".pdf"
                        elif "json" in mime:
                            ext = ".json"
                        elif "text" in mime or "markdown" in mime:
                            ext = ".txt"
                    filename = f"{item_type}-{i+1}{ext or ''}"
                dst = _safe_join(out_dir, filename)
                if os.path.exists(dst):
                    base, ext = os.path.splitext(filename)
                    dst = _safe_join(out_dir, f"{base}-{fp[:8] if 'fp' in locals() else uuid.uuid4().hex[:8]}{ext}")
                try:
                    with open(dst, "wb") as f:
                        f.write(raw)
                    saved.append(os.path.relpath(dst, session_dir))
                except Exception:
                    continue
            return saved

        def invoke_llm_live(
            *, prompt_messages: list[Any], tools: list[Any] | None
        ) -> Generator[ToolInvokeMessage, None, tuple[str, list[Any], Any, int, bool]]:
            nontext_content: list[dict[str, Any]] = []
            tool_calls_all: list[Any] = []
            text_parts: list[str] = []
            chunks_count = 0
            streamed_any = False
            saw_tool_calls = False
            typing_chunk = 6
            emitted_prefix = False
            emitted_len = 0

            def emit_typing(text: str) -> Generator[ToolInvokeMessage, None, None]:
                nonlocal streamed_any
                if not text:
                    return
                tagged = "\nã€ğŸ¤–Skill_Agentã€‘\n" + text.strip() + "\n\n"
                step = max(1, int(typing_chunk))
                for i in range(0, len(tagged), step):
                    yield self.create_text_message(tagged[i : i + step])
                    streamed_any = True
            
            def should_emit_user_text(text: str) -> bool:
                if not text:
                    return False
                s = str(text)
                stripped = s.lstrip()
                if stripped.startswith("{") and _extract_first_json_object(s) is None:
                    return False
                if stripped.startswith("```") and stripped.count("```") < 2:
                    return False
                json_text = _extract_first_json_object(text)
                if not json_text:
                    return True
                try:
                    obj = json.loads(json_text)
                except Exception:
                    return True
                if not isinstance(obj, dict):
                    return True
                t = obj.get("type")
                return t not in {"tool", "final"}

            try:
                try:
                    response = self.session.model.llm.invoke(
                        model_config=model,
                        prompt_messages=prompt_messages,
                        tools=tools,
                        stream=True,
                    )
                except TypeError:
                    response = self.session.model.llm.invoke(
                        model_config=model,
                        prompt_messages=prompt_messages,
                        stream=True,
                    )

                if _safe_get(response, "message") is not None:
                    msg = _safe_get(response, "message") or {}
                    content = _safe_get(msg, "content")
                    text, parts = _split_message_content(content)
                    if parts:
                        nontext_content.extend(parts)
                    tool_calls = _safe_get(msg, "tool_calls") or []
                    if isinstance(tool_calls, list):
                        tool_calls_all.extend(tool_calls)
                        if tool_calls:
                            saw_tool_calls = True
                    if text:
                        text_parts.append(text)
                    combined_text = "".join(text_parts).strip()
                    if combined_text and not saw_tool_calls and should_emit_user_text(combined_text):
                        yield from emit_typing(combined_text)
                    return combined_text, tool_calls_all, nontext_content, chunks_count, streamed_any

                for chunk in response:
                    chunks_count += 1
                    delta = _safe_get(chunk, "delta") or {}
                    msg = _safe_get(delta, "message") or {}
                    content = _safe_get(msg, "content")
                    t, parts = _split_message_content(content)
                    if parts:
                        nontext_content.extend(parts)
                    tc = _safe_get(msg, "tool_calls") or []
                    if isinstance(tc, list) and tc:
                        tool_calls_all.extend(tc)
                        if not saw_tool_calls:
                            saw_tool_calls = True
                    if t:
                        text_parts.append(t)
                        combined_text_live = "".join(text_parts).strip()
                        if combined_text_live and not saw_tool_calls and should_emit_user_text(combined_text_live):
                            if not emitted_prefix:
                                yield self.create_text_message("\nã€ğŸ¤–Skill_Agentã€‘\n")
                                emitted_prefix = True
                            new = combined_text_live[emitted_len:]
                            if new:
                                step = max(1, int(typing_chunk))
                                for i in range(0, len(new), step):
                                    yield self.create_text_message(new[i : i + step])
                                    streamed_any = True
                                emitted_len = len(combined_text_live)
                combined_text = "".join(text_parts).strip()
                if emitted_prefix:
                    yield self.create_text_message("\n\n")
                elif combined_text and not saw_tool_calls and should_emit_user_text(combined_text):
                    yield from emit_typing(combined_text)
                return combined_text, tool_calls_all, nontext_content, chunks_count, streamed_any
            except Exception as e:
                return "", [], {"error": "stream_parse_failed", "exception": str(e)}, chunks_count, streamed_any

        try:
            for step_idx in range(max_steps):
                compact()
                _dbg(f"step={step_idx+1}/{max_steps} messages={len(messages)}")
                try:
                    res_text, tool_calls, nontext, chunks, streamed_any = yield from invoke_llm_live(
                        prompt_messages=messages,
                        tools=_build_prompt_message_tools(TOOL_SCHEMAS, PromptMessageTool),
                    )
                except Exception as e:
                    msg = str(e)
                    if "NameResolutionError" in msg or "Failed to resolve" in msg:
                        yield self.create_text_message(
                            "âŒ LLM è°ƒç”¨å¤±è´¥ï¼šæ— æ³•è§£ææ¨¡å‹æœåŠ¡åŸŸåï¼ˆDNS/ç½‘ç»œé—®é¢˜ï¼‰ã€‚\n"
                            "å½“å‰æŠ¥é”™ä¿¡æ¯ï¼š\n"
                            + msg
                            + "\n\nè¯·æ£€æŸ¥ï¼š\n"
                            + "1) è¿è¡Œæ’ä»¶çš„ç¯å¢ƒæ˜¯å¦èƒ½è®¿é—®å…¬ç½‘/æ˜¯å¦éœ€è¦ä»£ç†\n"
                            + "2) DNS æ˜¯å¦å¯ç”¨ï¼ˆèƒ½å¦è§£æ dashscope.aliyuncs.com ç­‰åŸŸåï¼‰\n"
                            + "3) Dify çš„æ¨¡å‹ä¾›åº”å•†ï¼ˆé€šä¹‰ï¼‰ç½‘ç»œå‡ºç«™æ˜¯å¦è¢«é™åˆ¶\n"
                        )
                    else:
                        yield self.create_text_message("âŒ LLM è°ƒç”¨å¤±è´¥ï¼š\n" + msg)
                    return

                _dbg(
                    f"llm_return content_len={len(res_text)} tool_calls={len(tool_calls)} chunks={chunks} "
                    f"nontext={_shorten_text(nontext, 200) if nontext else ''}"
                )
                if nontext:
                    saved_assets = persist_llm_assets(nontext)
                    if saved_assets:
                        _dbg(f"nontext_assets_saved={len(saved_assets)} paths={_shorten_text(saved_assets, 300)}")
                if tool_calls:
                    empty_responses = 0
                    messages.append(AssistantPromptMessage(content=res_text or "", tool_calls=tool_calls))
                    forced_text: str | None = None
                    for tc in tool_calls:
                        call_id, name, arguments = _parse_tool_call(tc)
                        tool_name = str(name or "")
                        _dbg(f"tool_call name={tool_name} id={call_id!s} args={_shorten_text(arguments, 400)}")

                        ok_args, arg_detail = _validate_tool_arguments(tool_name, arguments)
                        if not ok_args:
                            result = {
                                "error": "invalid_tool_arguments",
                                "tool": tool_name,
                                "detail": arg_detail,
                                "got": arguments,
                            }
                            _dbg(f"tool_result name={tool_name} result={_shorten_text(result, 700)}")
                            messages.append(
                                ToolPromptMessage(
                                    tool_call_id=str(call_id or ""),
                                    name=tool_name,
                                    content=json.dumps(result, ensure_ascii=False),
                                )
                            )
                            messages.append(UserPromptMessage(content=_tool_call_retry_prompt(tool_name, arg_detail)))
                            continue

                        if tool_name in {"list_skill_files", "read_skill_file", "run_skill_command"}:
                            skill_name = str(arguments.get("skill_name") or "").strip()
                            if skill_name and not runtime.has_skill_metadata(skill_name):
                                result = {
                                    "error": "skill_md_required",
                                    "skill_name": skill_name,
                                    "detail": "å¿…é¡»å…ˆè°ƒç”¨ get_skill_metadata(skill_name) è¯»å– SKILL.mdï¼ˆè¯´æ˜ä¹¦ï¼‰åï¼Œæ‰èƒ½ç»§ç»­è°ƒç”¨è¯¥å·¥å…·ã€‚",
                                }
                                _dbg(f"tool_result name={tool_name} result={_shorten_text(result, 700)}")
                                messages.append(
                                    ToolPromptMessage(
                                        tool_call_id=str(call_id or ""),
                                        name=tool_name,
                                        content=json.dumps(result, ensure_ascii=False),
                                    )
                                )
                                messages.append(
                                    UserPromptMessage(
                                        content=(
                                            f"ä½ åˆšæ‰å°è¯•è°ƒç”¨ `{tool_name}` ä½†å°šæœªè¯»å–æŠ€èƒ½ã€Š{skill_name}ã€‹çš„ SKILL.mdã€‚"
                                            f"è¯·å…ˆè°ƒç”¨ get_skill_metadata({skill_name!r})ï¼Œå†é‡è¯•è¯¥å·¥å…·è°ƒç”¨ã€‚"
                                        )
                                    )
                                )
                                continue
                            if tool_name == "run_skill_command" and skill_name and not runtime.has_listed_skill_files(skill_name):
                                result = {
                                    "error": "skill_files_listing_required",
                                    "skill_name": skill_name,
                                    "detail": "æ‰§è¡ŒæŠ€èƒ½å‘½ä»¤å‰ï¼Œå¿…é¡»å…ˆè°ƒç”¨ list_skill_files(skill_name) æŸ¥çœ‹æŠ€èƒ½åŒ…ç›®å½•ç»“æ„ã€‚",
                                }
                                _dbg(f"tool_result name={tool_name} result={_shorten_text(result, 700)}")
                                messages.append(
                                    ToolPromptMessage(
                                        tool_call_id=str(call_id or ""),
                                        name=tool_name,
                                        content=json.dumps(result, ensure_ascii=False),
                                    )
                                )
                                messages.append(
                                    UserPromptMessage(
                                        content=(
                                            f"ä½ åˆšæ‰å°è¯•è°ƒç”¨ `{tool_name}` ä½†å°šæœªæŸ¥çœ‹æŠ€èƒ½ã€Š{skill_name}ã€‹çš„ç›®å½•ç»“æ„ã€‚"
                                            f"è¯·å…ˆè°ƒç”¨ list_skill_files({skill_name!r})ï¼Œå†é‡è¯•è¯¥å·¥å…·è°ƒç”¨ã€‚"
                                        )
                                    )
                                )
                                continue

                        if tool_name == "get_skill_metadata":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨æŸ¥çœ‹æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹è¯´æ˜ä¹¦â€¦\n"
                            )
                        elif tool_name == "list_skill_files":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨æŸ¥çœ‹æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹æ–‡ä»¶ç»“æ„â€¦\n"
                            )
                        elif tool_name == "read_skill_file":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨è¯»å–æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n"
                            )
                        elif tool_name == "run_skill_command":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨æ‰§è¡ŒæŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹å‘½ä»¤â€¦\n"
                            )
                        elif tool_name == "write_temp_file":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨æŒ‰è¯´æ˜ä¹¦å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n"
                            )
                        elif tool_name == "read_temp_file":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨è¯»å–ä¸´æ—¶æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n"
                            )
                        elif tool_name == "list_temp_files":
                            yield self.create_text_message("âœ…æ­£åœ¨æŸ¥çœ‹ä¸´æ—¶ç›®å½•æ–‡ä»¶â€¦\n")
                        elif tool_name == "run_temp_command":
                            yield self.create_text_message("âœ…æ­£åœ¨æ‰§è¡Œä¸´æ—¶å‘½ä»¤â€¦\n")
                        elif tool_name == "export_temp_file":
                            yield self.create_text_message(
                                f"âœ…æ­£åœ¨æ ‡è®°äº¤ä»˜æ–‡ä»¶ï¼š{str(arguments.get('temp_relative_path') or '')}â€¦\n"
                            )

                        if tool_name == "get_skill_metadata":
                            result = runtime.get_skill_metadata(str(arguments.get("skill_name") or ""))
                        elif tool_name == "list_skill_files":
                            result = runtime.list_skill_files(
                                str(arguments.get("skill_name") or ""),
                                int(arguments.get("max_depth") or 2),
                            )
                        elif tool_name == "read_skill_file":
                            result = runtime.read_skill_file(
                                str(arguments.get("skill_name") or ""),
                                str(arguments.get("relative_path") or ""),
                                int(arguments.get("max_chars") or 12000),
                            )
                        elif tool_name == "run_skill_command":
                            result = runtime.run_skill_command(
                                skill_name=str(arguments.get("skill_name") or ""),
                                command=arguments.get("command") if isinstance(arguments.get("command"), list) else [],
                                cwd_relative=(
                                    str(arguments.get("cwd_relative")) if arguments.get("cwd_relative") else None
                                ),
                                auto_install=bool(arguments.get("auto_install") or False),
                            )
                            if (
                                isinstance(result, dict)
                                and result.get("returncode") is not None
                                and int(result.get("returncode") or 0) != 0
                            ):
                                stderr = str(result.get("stderr") or "").strip()
                                if stderr:
                                    yield self.create_text_message(
                                        "âŒå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼ˆstderrï¼‰ï¼š\n" + _shorten_text(redact_user_visible_text(stderr), 1200) + "\n"
                                    )
                            if isinstance(result, dict) and result.get("error") == "no_executable_found":
                                skill = str(result.get("skill") or arguments.get("skill_name") or "")
                                module = str(result.get("module") or "")
                                forced_text = (
                                    f"å½“å‰æŠ€èƒ½â€œ{skill}â€çš„è¯´æ˜æ–‡æ¡£è¦æ±‚ç”Ÿæˆæ–‡ä»¶ï¼Œä½†æŠ€èƒ½åŒ…å†…æœªæ‰¾åˆ°å¯æ‰§è¡Œå…¥å£ï¼ˆä¾‹å¦‚è„šæœ¬æˆ– Python æ¨¡å—ï¼‰ã€‚\n"
                                    f"æœ¬æ¬¡å°è¯•çš„å…¥å£ä¸º python -m {module}ï¼Œä½†åœ¨æŠ€èƒ½ç›®å½•ä¸­ä¸å­˜åœ¨ï¼Œå› æ­¤æ— æ³•ç»§ç»­ç”Ÿæˆç›®æ ‡æ–‡ä»¶ã€‚\n\n"
                                    "æˆ‘å·²å…ˆæŒ‰æŠ€èƒ½è¯´æ˜ç”Ÿæˆäº†å¯äº¤ä»˜çš„ä¸­é—´äº§ç‰©ï¼ˆä¾‹å¦‚è®¾è®¡å“²å­¦ .mdï¼‰ã€‚\n"
                                    "ä½ æ˜¯å¦å…è®¸æˆ‘åœ¨ temp ç›®å½•ä¸­è‡ªè¡Œåˆ›å»ºå¯æ‰§è¡Œè„šæœ¬ï¼Œå¹¶åœ¨éœ€è¦æ—¶å®‰è£…ä¾èµ–åï¼Œå†å°è¯•ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶ï¼Ÿ"
                                )
                                _storage_set_json(
                                    storage,
                                    resume_key,
                                    {
                                        "pending": True,
                                        "session_dir": session_dir,
                                        "original_query": query,
                                        "reason": "no_executable_found",
                                        "skill": skill,
                                        "module": module,
                                        "created_at": int(time.time()),
                                    },
                                )
                                resume_saved = True
                                _dbg(
                                    "resume_state_saved "
                                    + _shorten_text(
                                        {"session_dir": session_dir, "skill": skill, "module": module, "pending": True},
                                        300,
                                    )
                                )
                        elif tool_name == "get_session_context":
                            result = runtime.get_session_context()
                        elif tool_name == "write_temp_file":
                            result = runtime.write_temp_file(
                                str(arguments.get("relative_path") or ""),
                                str(arguments.get("content") or ""),
                            )
                        elif tool_name == "read_temp_file":
                            result = runtime.read_temp_file(
                                str(arguments.get("relative_path") or ""),
                                int(arguments.get("max_chars") or 12000),
                            )
                        elif tool_name == "list_temp_files":
                            result = runtime.list_temp_files(int(arguments.get("max_depth") or 4))
                        elif tool_name == "run_temp_command":
                            result = runtime.run_temp_command(
                                command=arguments.get("command") if isinstance(arguments.get("command"), list) else [],
                                cwd_relative=(
                                    str(arguments.get("cwd_relative")) if arguments.get("cwd_relative") else None
                                ),
                                auto_install=bool(arguments.get("auto_install") or False),
                            )
                            if (
                                isinstance(result, dict)
                                and result.get("returncode") is not None
                                and int(result.get("returncode") or 0) != 0
                            ):
                                stderr = str(result.get("stderr") or "").strip()
                                if stderr:
                                    yield self.create_text_message(
                                        "âŒå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼ˆstderrï¼‰ï¼š\n" + _shorten_text(redact_user_visible_text(stderr), 1200) + "\n"
                                    )
                        elif tool_name == "export_temp_file":
                            temp_rel = str(arguments.get("temp_relative_path") or "")
                            workspace_rel = str(arguments.get("workspace_relative_path") or "")
                            result = runtime.export_temp_file(
                                temp_relative_path=temp_rel,
                                workspace_relative_path=workspace_rel,
                                overwrite=bool(arguments.get("overwrite") or False),
                            )
                            out_name = os.path.basename(workspace_rel) if workspace_rel else ""
                            if (
                                isinstance(result, dict)
                                and not result.get("error")
                                and temp_rel
                                and out_name
                            ):
                                final_file_meta[temp_rel] = {
                                    **(final_file_meta.get(temp_rel) or {}),
                                    "filename": out_name,
                                    "mime_type": _guess_mime_type(out_name),
                                }
                        else:
                            result = {"error": f"unknown tool: {tool_name}"}

                        _dbg(f"tool_result name={tool_name} result={_shorten_text(result, 700)}")
                        messages.append(
                            ToolPromptMessage(
                                tool_call_id=str(call_id or ""),
                                name=tool_name,
                                content=json.dumps(result, ensure_ascii=False),
                            )
                        )
                    if forced_text:
                        final_text = forced_text
                        break
                    if step_idx >= max_steps - 1:
                        try:
                            has_files = any(
                                e.get("type") == "file"
                                for e in _list_dir(session_dir, max_depth=2)
                                if isinstance(e, dict)
                            )
                        except Exception:
                            has_files = False
                        if final_file_meta or has_files:
                            final_text = "å·²ç”Ÿæˆæ–‡ä»¶ã€‚"
                            break
                    continue

                json_text = _extract_first_json_object(res_text)
                action: dict[str, Any] | None = None
                if json_text:
                    try:
                        action = json.loads(json_text)
                    except Exception:
                        action = None
                _dbg(f"json_protocol detected={bool(action)} snippet={_shorten_text(json_text or '', 200)}")

                if not res_text and not action and not nontext:
                    empty_responses += 1
                    _dbg(f"empty_response_count={empty_responses}")
                    if empty_responses < 3:
                        messages.append(
                            UserPromptMessage(
                                content='ä½ åˆšæ‰æ²¡æœ‰è¾“å‡ºä»»ä½•å†…å®¹ã€‚è¯·ç»§ç»­å®Œæˆä»»åŠ¡ï¼šå¦‚æœæ”¯æŒå‡½æ•°è°ƒç”¨è¯·è°ƒç”¨å·¥å…·ï¼›å¦åˆ™è¯·è¾“å‡º JSONï¼š{"type":"final","content":"..."}'
                            )
                        )
                        continue
                    final_text = "æ¨¡å‹è¿ç»­è¿”å›ç©ºå“åº”ï¼Œæœªç”Ÿæˆä»»ä½•ç»“æœã€‚"
                    break

                if not action or action.get("type") == "final":
                    if action and action.get("type") == "final":
                        final_text = str(action.get("content") or "")
                        _dbg(f"final_json content_len={len(final_text)}")
                    else:
                        final_text = res_text
                        _dbg(f"final_text content_len={len(final_text)}")
                        if streamed_any and final_text:
                            final_text_already_streamed = True
                    break

                if action.get("type") != "tool":
                    final_text = res_text
                    _dbg(f"final_non_tool type={action.get('type')!s} content_len={len(final_text)}")
                    break

                name = str(action.get("name") or "")
                arguments = action.get("arguments") or {}
                if not isinstance(arguments, dict):
                    arguments = {}

                ok_args, arg_detail = _validate_tool_arguments(name, arguments)
                if not ok_args:
                    messages.append(UserPromptMessage(content=_tool_call_retry_prompt(name, arg_detail)))
                    result = {
                        "error": "invalid_tool_arguments",
                        "tool": name,
                        "detail": arg_detail,
                        "got": arguments,
                    }
                    _dbg(f"json_tool_result name={name} result={_shorten_text(result, 700)}")
                    messages.append(
                        AssistantPromptMessage(
                            content="TOOL_RESULT\n" + json.dumps({"name": name, "result": result}, ensure_ascii=False)
                        )
                    )
                    continue

                if name in {"list_skill_files", "read_skill_file", "run_skill_command"}:
                    skill_name = str(arguments.get("skill_name") or "").strip()
                    if skill_name and not runtime.has_skill_metadata(skill_name):
                        messages.append(
                            UserPromptMessage(
                                content=(
                                    f"ä½ åˆšæ‰å°è¯•è°ƒç”¨ `{name}` ä½†å°šæœªè¯»å–æŠ€èƒ½ã€Š{skill_name}ã€‹çš„ SKILL.mdã€‚"
                                    f"è¯·å…ˆè°ƒç”¨ get_skill_metadata({skill_name!r})ï¼Œå†é‡è¯•è¯¥å·¥å…·è°ƒç”¨ã€‚"
                                )
                            )
                        )
                        result = {
                            "error": "skill_md_required",
                            "skill_name": skill_name,
                            "detail": "å¿…é¡»å…ˆè°ƒç”¨ get_skill_metadata(skill_name) è¯»å– SKILL.mdï¼ˆè¯´æ˜ä¹¦ï¼‰åï¼Œæ‰èƒ½ç»§ç»­è°ƒç”¨è¯¥å·¥å…·ã€‚",
                        }
                        _dbg(f"json_tool_result name={name} result={_shorten_text(result, 700)}")
                        messages.append(
                            AssistantPromptMessage(
                                content="TOOL_RESULT\n" + json.dumps({"name": name, "result": result}, ensure_ascii=False)
                            )
                        )
                        continue
                    if name == "run_skill_command" and skill_name and not runtime.has_listed_skill_files(skill_name):
                        messages.append(
                            UserPromptMessage(
                                content=(
                                    f"ä½ åˆšæ‰å°è¯•è°ƒç”¨ `{name}` ä½†å°šæœªæŸ¥çœ‹æŠ€èƒ½ã€Š{skill_name}ã€‹çš„ç›®å½•ç»“æ„ã€‚"
                                    f"è¯·å…ˆè°ƒç”¨ list_skill_files({skill_name!r})ï¼Œå†é‡è¯•è¯¥å·¥å…·è°ƒç”¨ã€‚"
                                )
                            )
                        )
                        result = {
                            "error": "skill_files_listing_required",
                            "skill_name": skill_name,
                            "detail": "æ‰§è¡ŒæŠ€èƒ½å‘½ä»¤å‰ï¼Œå¿…é¡»å…ˆè°ƒç”¨ list_skill_files(skill_name) æŸ¥çœ‹æŠ€èƒ½åŒ…ç›®å½•ç»“æ„ã€‚",
                        }
                        _dbg(f"json_tool_result name={name} result={_shorten_text(result, 700)}")
                        messages.append(
                            AssistantPromptMessage(
                                content="TOOL_RESULT\n" + json.dumps({"name": name, "result": result}, ensure_ascii=False)
                            )
                        )
                        continue

                _dbg(f"json_tool name={name} args={_shorten_text(arguments, 400)}")
                messages.append(AssistantPromptMessage(content=json.dumps(action, ensure_ascii=False)))

                if name == "get_skill_metadata":
                    yield self.create_text_message(f"âœ…æ­£åœ¨æŸ¥çœ‹æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹è¯´æ˜ä¹¦â€¦\n")
                elif name == "list_skill_files":
                    yield self.create_text_message(f"âœ…æ­£åœ¨æŸ¥çœ‹æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹æ–‡ä»¶ç»“æ„â€¦\n")
                elif name == "read_skill_file":
                    yield self.create_text_message(
                        f"âœ…æ­£åœ¨è¯»å–æŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n"
                    )
                elif name == "run_skill_command":
                    yield self.create_text_message(
                        f"âœ…æ­£åœ¨æ‰§è¡ŒæŠ€èƒ½ã€Š{str(arguments.get('skill_name') or '')}ã€‹å‘½ä»¤â€¦\n"
                    )
                elif name == "write_temp_file":
                    yield self.create_text_message(f"âœ…æ­£åœ¨æŒ‰è¯´æ˜ä¹¦å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n")
                elif name == "read_temp_file":
                    yield self.create_text_message(f"âœ…æ­£åœ¨è¯»å–ä¸´æ—¶æ–‡ä»¶ï¼š{str(arguments.get('relative_path') or '')}â€¦\n")
                elif name == "list_temp_files":
                    yield self.create_text_message("âœ…æ­£åœ¨æŸ¥çœ‹ä¸´æ—¶ç›®å½•æ–‡ä»¶â€¦\n")
                elif name == "run_temp_command":
                    yield self.create_text_message("âœ…æ­£åœ¨æ‰§è¡Œä¸´æ—¶å‘½ä»¤â€¦\n")
                elif name == "export_temp_file":
                    yield self.create_text_message(f"âœ…æ­£åœ¨æ ‡è®°äº¤ä»˜æ–‡ä»¶ï¼š{str(arguments.get('temp_relative_path') or '')}â€¦\n")

                if name == "get_skill_metadata":
                    result = runtime.get_skill_metadata(str(arguments.get("skill_name") or ""))
                elif name == "list_skill_files":
                    result = runtime.list_skill_files(
                        str(arguments.get("skill_name") or ""),
                        int(arguments.get("max_depth") or 2),
                    )
                elif name == "read_skill_file":
                    result = runtime.read_skill_file(
                        str(arguments.get("skill_name") or ""),
                        str(arguments.get("relative_path") or ""),
                        int(arguments.get("max_chars") or 12000),
                    )
                elif name == "run_skill_command":
                    result = runtime.run_skill_command(
                        skill_name=str(arguments.get("skill_name") or ""),
                        command=arguments.get("command") if isinstance(arguments.get("command"), list) else [],
                        cwd_relative=(str(arguments.get("cwd_relative")) if arguments.get("cwd_relative") else None),
                        auto_install=bool(arguments.get("auto_install") or False),
                    )
                elif name == "get_session_context":
                    result = runtime.get_session_context()
                elif name == "write_temp_file":
                    result = runtime.write_temp_file(
                        str(arguments.get("relative_path") or ""),
                        str(arguments.get("content") or ""),
                    )
                elif name == "read_temp_file":
                    result = runtime.read_temp_file(
                        str(arguments.get("relative_path") or ""),
                        int(arguments.get("max_chars") or 12000),
                    )
                elif name == "list_temp_files":
                    result = runtime.list_temp_files(int(arguments.get("max_depth") or 4))
                elif name == "run_temp_command":
                    result = runtime.run_temp_command(
                        command=arguments.get("command") if isinstance(arguments.get("command"), list) else [],
                        cwd_relative=(str(arguments.get("cwd_relative")) if arguments.get("cwd_relative") else None),
                        auto_install=bool(arguments.get("auto_install") or False),
                    )
                elif name == "export_temp_file":
                    temp_rel = str(arguments.get("temp_relative_path") or "")
                    workspace_rel = str(arguments.get("workspace_relative_path") or "")
                    result = runtime.export_temp_file(
                        temp_relative_path=temp_rel,
                        workspace_relative_path=workspace_rel,
                        overwrite=bool(arguments.get("overwrite") or False),
                    )
                    out_name = os.path.basename(workspace_rel) if workspace_rel else ""
                    if (
                        isinstance(result, dict)
                        and not result.get("error")
                        and temp_rel
                        and out_name
                    ):
                        final_file_meta[temp_rel] = {
                            **(final_file_meta.get(temp_rel) or {}),
                            "filename": out_name,
                            "mime_type": _guess_mime_type(out_name),
                        }
                else:
                    result = {"error": f"unknown tool: {name}"}

                _dbg(f"json_tool_result name={name} result={_shorten_text(result, 700)}")
                messages.append(
                    AssistantPromptMessage(
                        content="TOOL_RESULT\n" + json.dumps({"name": name, "result": result}, ensure_ascii=False)
                    )
                )
            else:
                try:
                    has_files = any(
                        e.get("type") == "file" for e in _list_dir(session_dir, max_depth=2) if isinstance(e, dict)
                    )
                except Exception:
                    has_files = False
                if final_file_meta or has_files:
                    final_text = "å·²ç”Ÿæˆæ–‡ä»¶ã€‚"
                else:
                    final_text = f"âŒè¶…è¿‡æœ€å¤§æ‰§è¡Œè½®æ•° max_steps={max_steps}ï¼Œä»æœªå¾—åˆ°æœ€ç»ˆç»“æœ"
        finally:
            if not resume_saved and not is_resuming and resume_pending:
                _storage_set_json(storage, resume_key, None)
            temp_files_text = ""
            try:
                temp_entries = _list_dir(session_dir, max_depth=10)
                rel_paths = [
                    str(e.get("relative_path"))
                    for e in temp_entries
                    if e.get("type") == "file" and isinstance(e.get("relative_path"), str)
                ]
                if rel_paths:
                    temp_files_text = "\n\n[temp_files]\n" + "\n".join(rel_paths)
                _dbg(f"temp_files_count={len(rel_paths)}")
            except Exception:
                temp_files_text = ""

            files_to_send: list[tuple[str, str, str, str]] = []
            try:
                for rel, meta_override in (final_file_meta or {}).items():
                    if not rel or not isinstance(rel, str):
                        continue
                    rel_norm = rel.replace("\\", "/").lstrip("/")
                    if not rel_norm:
                        continue
                    try:
                        path = _safe_join(session_dir, rel_norm)
                    except Exception:
                        continue
                    if not os.path.isfile(path):
                        continue
                    filename = os.path.basename(rel_norm)
                    out_name = (meta_override.get("filename") if isinstance(meta_override, dict) else None) or filename
                    mime_type = (meta_override.get("mime_type") if isinstance(meta_override, dict) else None) or _guess_mime_type(out_name or filename)
                    files_to_send.append((rel_norm, path, mime_type, out_name))
            except Exception:
                files_to_send = []

            has_any_files = False
            try:
                temp_entries = _list_dir(session_dir, max_depth=10)
                has_any_files = any(e.get("type") == "file" for e in temp_entries if isinstance(e, dict))
            except Exception:
                has_any_files = False

            assistant_text_for_history = ""
            if final_text and final_text.strip():
                if not files_to_send and final_text.strip() == "å·²ç”Ÿæˆæ–‡ä»¶ã€‚":
                    final_text = "å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶ï¼Œä½†æœªè°ƒç”¨ export_temp_file æ ‡è®°äº¤ä»˜æ–‡ä»¶ã€‚"
                assistant_text_for_history = final_text.strip()
                _append_history_turn(
                    storage,
                    history_key=history_key,
                    user_text=user_input,
                    assistant_text=assistant_text_for_history,
                )
                if not final_text_already_streamed:
                    yield from stream_text_to_user(final_text)
            elif files_to_send:
                assistant_text_for_history = "å·²ç”Ÿæˆæ–‡ä»¶ã€‚"
                _append_history_turn(
                    storage,
                    history_key=history_key,
                    user_text=user_input,
                    assistant_text=assistant_text_for_history,
                )
                yield from stream_text_to_user("å·²ç”Ÿæˆæ–‡ä»¶ã€‚")
            elif has_any_files:
                assistant_text_for_history = "å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶ï¼Œä½†æœªè°ƒç”¨ export_temp_file æ ‡è®°äº¤ä»˜æ–‡ä»¶ã€‚"
                _append_history_turn(
                    storage,
                    history_key=history_key,
                    user_text=user_input,
                    assistant_text=assistant_text_for_history,
                )
                yield from stream_text_to_user("å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶ï¼Œä½†æœªè°ƒç”¨ export_temp_file æ ‡è®°äº¤ä»˜æ–‡ä»¶ã€‚")
            else:
                assistant_text_for_history = "æœªç”Ÿæˆä»»ä½•æ–‡æœ¬æˆ–æ–‡ä»¶è¾“å‡ºã€‚"
                _append_history_turn(
                    storage,
                    history_key=history_key,
                    user_text=user_input,
                    assistant_text=assistant_text_for_history,
                )
                yield from stream_text_to_user("æœªç”Ÿæˆä»»ä½•æ–‡æœ¬æˆ–æ–‡ä»¶è¾“å‡ºã€‚")

            yielded: set[str] = set()
            yielded_fingerprints: set[str] = set()
            for rel, path, mime_type, out_name in files_to_send:
                if rel in yielded:
                    continue
                yielded.add(rel)
                try:
                    with open(path, "rb") as fp:
                        content = fp.read()
                    try:
                        content_fp = hashlib.sha1(content).hexdigest()
                    except Exception:
                        content_fp = str(len(content))
                    fingerprint_key = f"{out_name}|{mime_type}|{content_fp}"
                    if fingerprint_key in yielded_fingerprints:
                        continue
                    yielded_fingerprints.add(fingerprint_key)
                    yield self.create_blob_message(blob=content, meta={"mime_type": mime_type, "filename": out_name})
                except Exception:
                    continue
            _dbg(f"temp_retained session_dir={session_dir}")
